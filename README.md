# DDPM: Denoising Diffusion Probabilistic Models

A complete implementation of Denoising Diffusion Probabilistic Models (DDPM) for image generation, with comprehensive benchmarking tools and organized codebase structure.

## ğŸ“ Repository Structure

```
DDPM/
â”œâ”€â”€ ğŸ“‹ README.md                      # This file
â”œâ”€â”€ ğŸ”§ setup.py                       # Package installation
â”œâ”€â”€ ğŸ“¦ requirements.txt               # Dependencies
â”œâ”€â”€ ğŸš« .gitignore                     # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“¦ ddpm/                          # Core DDPM package
â”‚   â”œâ”€â”€ ğŸ§  models/                    # Model implementations
â”‚   â”‚   â”œâ”€â”€ diffusion.py              # GaussianDiffusion class
â”‚   â”‚   â””â”€â”€ unet.py                   # U-Net architecture
â”‚   â”œâ”€â”€ ğŸ¯ training/                  # Training utilities
â”‚   â”‚   â”œâ”€â”€ ema.py                    # Exponential Moving Average
â”‚   â”‚   â””â”€â”€ utils.py                  # Training utilities
â”‚   â””â”€â”€ ğŸ”§ utils/                     # Utility functions
â”‚       â””â”€â”€ script_utils.py           # Script helpers
â”‚
â”œâ”€â”€ ğŸš€ scripts/                       # Training & inference scripts
â”‚   â”œâ”€â”€ train/                        # Training scripts
â”‚   â”‚   â”œâ”€â”€ train_cifar.py            # Single GPU CIFAR-10 training
â”‚   â”‚   â””â”€â”€ train_cifar_distributed.py # Multi-GPU training
â”‚   â”œâ”€â”€ inference/                    # Inference scripts
â”‚   â”‚   â””â”€â”€ sample_images.py          # Generate samples
â”‚   â””â”€â”€ launcher_scripts/             # Launcher utilities
â”‚       â””â”€â”€ launch_distributed_training.sh
â”‚
â”œâ”€â”€ ğŸ“Š benchmarks/                    # GPU benchmarking system
â”‚   â”œâ”€â”€ benchmark_gpu_training.py     # Core benchmark script
â”‚   â”œâ”€â”€ test_benchmark_setup.py       # Setup verification
â”‚   â”œâ”€â”€ scripts/                      # Benchmark launchers
â”‚   â”‚   â”œâ”€â”€ run_gpu_benchmark.sh      # Full benchmark
â”‚   â”‚   â””â”€â”€ demo_benchmark.sh         # Quick demo
â”‚   â””â”€â”€ README.md                     # Benchmark documentation
â”‚
â”œâ”€â”€ ğŸ§ª tests/                         # Test files
â”‚   â””â”€â”€ test_setup.py                 # Environment tests
â”‚
â”œâ”€â”€ ğŸ”§ tools/                         # Utility tools
â”‚   â”œâ”€â”€ activate_ddpm_env.sh          # Environment activation
â”‚   â”œâ”€â”€ show_benchmark_summary.py     # Benchmark summary
â”‚   â””â”€â”€ get-pip.py                    # Pip installer
â”‚
â””â”€â”€ ğŸ“š docs/                          # Documentation & resources
    â””â”€â”€ resources/                    # Papers, slides, examples
        â”œâ”€â”€ diffusion_models_report.pdf
        â”œâ”€â”€ diffusion_models_talk_slides.pdf
        â”œâ”€â”€ diffusion_sequence_mnist.gif
        â””â”€â”€ samples_linear_200.png
```

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Clone the repository
git clone https://github.com/dongwookim-ml/DDPM.git
cd DDPM

# Activate environment
source tools/activate_ddpm_env.sh
```

### 2. Training
```bash
# Single GPU training
python scripts/train/train_cifar.py --iterations 100000 --batch_size 128

# Multi-GPU training  
bash scripts/launcher_scripts/launch_distributed_training.sh

# Or use the training script directly
python scripts/train/train_cifar_distributed.py --iterations 100000 --batch_size 64
```

### 3. Inference
```bash
# Generate samples from trained model
python scripts/inference/sample_images.py --model_path path/to/checkpoint.pth
```

### 4. Benchmarking
```bash
# Quick demo (recommended first)
bash benchmarks/scripts/demo_benchmark.sh

# Full GPU benchmark (1 GPU vs 8 GPUs)
bash benchmarks/scripts/run_gpu_benchmark.sh

# Custom benchmark
bash benchmarks/scripts/run_gpu_benchmark.sh --batch_size 32 --num_workers 8
```

## ğŸ“Š Features

### Core Implementation
- **Complete DDPM implementation** with U-Net architecture
- **Support for conditional and unconditional generation**
- **Exponential Moving Average (EMA)** for stable training
- **Multiple noise schedules** (linear, cosine)
- **Distributed training** with PyTorch DDP

### Benchmarking System
- **1 GPU vs 8 GPU performance comparison**
- **Real-time performance monitoring**
- **Comprehensive metrics** (throughput, scaling efficiency, memory usage)
- **Automatic visualization generation**
- **CSV and JSON result export**

### Developer Tools
- **Organized modular structure**
- **Comprehensive testing suite**
- **Environment management tools**
- **Documentation and examples**

## ğŸ”§ Installation

### Requirements
- Python 3.8+
- CUDA-capable GPU(s)
- PyTorch 2.0+

### Setup
```bash
# Install package in development mode
pip install -e .

# Or install from requirements
pip install -r requirements.txt
```

## ğŸ“š Documentation

- **Benchmarking**: See `benchmarks/README.md` for detailed benchmarking documentation
- **Training**: Check `scripts/train/` for training examples
- **Models**: Explore `ddpm/models/` for model implementations
- **Resources**: Find papers and examples in `docs/resources/`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes following the modular structure
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project implements the DDPM algorithm from:
- **Paper**: "Denoising Diffusion Probabilistic Models" by Ho et al. (2020)
- **ArXiv**: https://arxiv.org/abs/2006.11239

## ğŸ† Performance

With 8x RTX 3090 GPUs:
- **Training speedup**: ~6-7x compared to single GPU
- **Scaling efficiency**: ~75-85%
- **Memory usage**: ~8-12GB per GPU
- **Throughput**: ~500-1000 samples/second

## ğŸ”— Links

- [Original DDPM Paper](https://arxiv.org/abs/2006.11239)
- [Repository](https://github.com/dongwookim-ml/DDPM)
- [Issues](https://github.com/dongwookim-ml/DDPM/issues)
